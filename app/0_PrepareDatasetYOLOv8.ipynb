{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Immport\n",
    "from xml.dom import minidom\n",
    "import bs4 as bs\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRM_INPUT_ROOT_PATH = 'datasets_raw'\n",
    "PRM_OUTPUT_ROOT_PATH = 'datasets'\n",
    "PRM_OUTPUT_BASE_PATH = 'labels/val'\n",
    "PRM_OUTPUT_MAIN_PATH = f'{PRM_OUTPUT_ROOT_PATH}/{PRM_OUTPUT_BASE_PATH}'\n",
    "PRM_WORDS_TO_IGNORE = ['Zone.Identifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_words(list_of_words):\n",
    "  for filter_word in PRM_WORDS_TO_IGNORE:\n",
    "    list_of_words = [word for word in list_of_words if filter_word.upper() not in word.upper()]\n",
    "  return list_of_words\n",
    "\n",
    "def get_nasty_files(list_of_words):\n",
    "  for filter_word in PRM_WORDS_TO_IGNORE:\n",
    "    list_of_words = [word for word in list_of_words if filter_word.upper() in word.upper()]\n",
    "  return list_of_words\n",
    "\n",
    "def delete_nasty_files(path):\n",
    "  # get files list\n",
    "  if os.path.exists(path):\n",
    "    list_files = os.listdir(path)\n",
    "\n",
    "    # gest nasty files\n",
    "    nasty_files = get_nasty_files(list_files)\n",
    "\n",
    "    # validate if exists then remove it\n",
    "    if len(nasty_files) > 0:\n",
    "      for file in nasty_files:\n",
    "        file_path = f'{path}/{file}'\n",
    "        # check if exists\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertPascal2YOLOv8(filePath):\n",
    "\n",
    "    class_mapping = {\n",
    "        \"D00\": 0,\n",
    "        \"D10\": 1,\n",
    "        \"D20\": 2,\n",
    "        \"D40\": 3,\n",
    "        \"D01\": 4,\n",
    "        \"D11\": 5,\n",
    "        \"D43\": 6,\n",
    "        \"D44\": 7,\n",
    "        \"D50\": 8\n",
    "    }\n",
    "    \n",
    "    # reading content\n",
    "    file = open(filePath, \"r\")\n",
    "    contents = file.read()\n",
    "\n",
    "    # parsing\n",
    "    soup = bs.BeautifulSoup(contents, 'xml')\n",
    "    image_size = soup.find_all(\"size\")[0]\n",
    "    image_width = int(image_size.find_all(\"width\")[0].get_text())\n",
    "    image_height = int(image_size.find_all(\"height\")[0].get_text())\n",
    "    # print(\"w,h :\", image_width, image_height)\n",
    "\n",
    "    # Process Bounding Box\n",
    "    objects = soup.find_all(\"object\")\n",
    "\n",
    "    # Placeholder\n",
    "    bounding_box_list = []\n",
    "    class_list = []\n",
    "\n",
    "    for object in objects:\n",
    "        \n",
    "        # Object Class\n",
    "        _class = object.find_all(\"name\")[0].get_text()\n",
    "        \n",
    "        # Map the class to int number, if not defined > 10\n",
    "        _class = class_mapping.get(_class, 10)\n",
    "        class_list.append(_class)\n",
    "        \n",
    "        # Object Bounding Box\n",
    "        _xmin = float(object.find_all(\"xmin\")[0].get_text())\n",
    "        _ymin = float(object.find_all(\"ymin\")[0].get_text())\n",
    "        _xmax = float(object.find_all(\"xmax\")[0].get_text())\n",
    "        _ymax = float(object.find_all(\"ymax\")[0].get_text())\n",
    "\n",
    "        # Convert to YOLOv8 Annotation\n",
    "        # class x_center y_center width height\n",
    "        w = (_xmax - _xmin)\n",
    "        h = (_ymax - _ymin)\n",
    "        cx = _xmin + (w/2)\n",
    "        cy = _ymin + (h/2)\n",
    "\n",
    "        # Normalize\n",
    "        w = round((w / image_width), 4)\n",
    "        h = round((h / image_height), 4)\n",
    "        cx = round((cx / image_width), 4)\n",
    "        cy = round((cy / image_height), 4)\n",
    "\n",
    "        _bbox = [cx, cy, w, h]\n",
    "\n",
    "        # print(_class, cx, cy, w, h)\n",
    "\n",
    "        bounding_box_list.append(_bbox)\n",
    "\n",
    "    # Get the filename\n",
    "    outputFilename = os.path.split(filePath)[1]\n",
    "    outputFilename = outputFilename.replace(\".xml\", \".txt\")\n",
    "\n",
    "    # Output Path\n",
    "    outputDir = Path(filePath).parents[2]\n",
    "    outputDir = outputDir / \"labels\"\n",
    "\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(outputDir):\n",
    "        os.makedirs(outputDir)\n",
    "\n",
    "    # Final output path\n",
    "    outputPath = outputDir / outputFilename\n",
    "    # print(outputPath)\n",
    "\n",
    "    # Write to .txt file\n",
    "    with open(outputPath, 'w') as f:\n",
    "        for i in range(len(class_list)):\n",
    "\n",
    "            # Filter the class, drop unused class\n",
    "            # 0: D00 > Longitudinal Crack\n",
    "            # 1: D10 > Transverse Crack\n",
    "            # 2: D20 > Alligator Crack\n",
    "            # 3: D40 > Potholes\n",
    "            \n",
    "            if class_list[i] < 4:\n",
    "                anno = str(class_list[i]) + \" \" +  str(bounding_box_list[i][0]) + \" \" +  str(bounding_box_list[i][1]) + \" \" +  str(bounding_box_list[i][2]) + \" \" +  str(bounding_box_list[i][3]) + \"\\n\"\n",
    "                f.write(anno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove nasty files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Root Directory\n",
    "ROOTDIR = \"datasets_raw\"\n",
    "\n",
    "country_dir = [\"RDD2022_all_countries/Japan/Japan\",\n",
    "               \"RDD2022_all_countries/India/India\",\n",
    "               \"RDD2022_all_countries/China_Drone/China_Drone\",\n",
    "               \"RDD2022_all_countries/China_MotorBike/China_MotorBike\",\n",
    "               \"RDD2022_all_countries/Czech/Czech\",\n",
    "               \"RDD2022_all_countries/Norway/Norway\",\n",
    "               \"RDD2022_all_countries/United_States/United_States\"]\n",
    "\n",
    "sufix_dir = ['train/images',\n",
    "             'train/annotations/xmls',\n",
    "             'test/images']\n",
    "\n",
    "for country in country_dir:\n",
    "    for sufix in sufix_dir:\n",
    "        path_to_delete = f'{ROOTDIR}/{country}/{sufix}'\n",
    "        delete_nasty_files(path_to_delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Train_size</th>\n",
       "      <th>Test_size</th>\n",
       "      <th>Label_size</th>\n",
       "      <th>Total_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japan</td>\n",
       "      <td>10506</td>\n",
       "      <td>2627</td>\n",
       "      <td>10506</td>\n",
       "      <td>13133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India</td>\n",
       "      <td>7706</td>\n",
       "      <td>1959</td>\n",
       "      <td>7706</td>\n",
       "      <td>9665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China_Drone</td>\n",
       "      <td>2401</td>\n",
       "      <td>0</td>\n",
       "      <td>2401</td>\n",
       "      <td>2401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>China_MotorBike</td>\n",
       "      <td>1977</td>\n",
       "      <td>500</td>\n",
       "      <td>1977</td>\n",
       "      <td>2477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Czech</td>\n",
       "      <td>2829</td>\n",
       "      <td>709</td>\n",
       "      <td>2829</td>\n",
       "      <td>3538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Norway</td>\n",
       "      <td>8161</td>\n",
       "      <td>2040</td>\n",
       "      <td>8161</td>\n",
       "      <td>10201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>United_States</td>\n",
       "      <td>4805</td>\n",
       "      <td>1200</td>\n",
       "      <td>4805</td>\n",
       "      <td>6005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Country  Train_size  Test_size  Label_size  Total_size\n",
       "0            Japan       10506       2627       10506       13133\n",
       "1            India        7706       1959        7706        9665\n",
       "2      China_Drone        2401          0        2401        2401\n",
       "3  China_MotorBike        1977        500        1977        2477\n",
       "4            Czech        2829        709        2829        3538\n",
       "5           Norway        8161       2040        8161       10201\n",
       "6    United_States        4805       1200        4805        6005"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declare list that stores records\n",
    "records = list()\n",
    "\n",
    "for country in country_dir:\n",
    "    path_train = f'{ROOTDIR}/{country}/train/images'\n",
    "    path_test = f'{ROOTDIR}/{country}/test/images'\n",
    "    path_labels = f'{ROOTDIR}/{country}/train/annotations/xmls'\n",
    "\n",
    "    record = dict()\n",
    "    record['Country'] = country.split('/')[1]\n",
    "    record['Train_size'] = len(os.listdir(path_train)) if os.path.exists(path_train) else 0\n",
    "    record['Test_size'] = len(os.listdir(path_test)) if os.path.exists(path_test) else 0\n",
    "    record['Label_size'] = len(os.listdir(path_labels)) if os.path.exists(path_labels) else 0\n",
    "\n",
    "    # save record\n",
    "    records.append(record)\n",
    "\n",
    "records = pd.DataFrame(records)\n",
    "records['Total_size'] = records['Train_size'] + records['Test_size']\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Train_size    38385\n",
       "Test_size      9035\n",
       "Label_size    38385\n",
       "Total_size    47420\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.drop(columns = 'Country').sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10506/10506 [00:09<00:00, 1066.24it/s]\n",
      "100%|██████████| 7706/7706 [00:04<00:00, 1648.84it/s]\n",
      "100%|██████████| 2401/2401 [00:01<00:00, 1286.58it/s]\n",
      "100%|██████████| 1977/1977 [00:01<00:00, 988.58it/s] \n",
      "100%|██████████| 2829/2829 [00:01<00:00, 2247.12it/s]\n",
      "100%|██████████| 8161/8161 [00:06<00:00, 1202.66it/s]\n",
      "100%|██████████| 4805/4805 [00:04<00:00, 1070.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Dataset Root Directory\n",
    "ROOTDIR = \"datasets_raw/\"\n",
    "\n",
    "# Base Directory\n",
    "CountryListDir = [\"RDD2022_all_countries/Japan/Japan/train/annotations/xmls\",\n",
    "                  \"RDD2022_all_countries/India/India/train/annotations/xmls\",\n",
    "                  \"RDD2022_all_countries/China_Drone/China_Drone/train/annotations/xmls\",\n",
    "                  \"RDD2022_all_countries/China_MotorBike/China_MotorBike/train/annotations/xmls\",\n",
    "                  \"RDD2022_all_countries/Czech/Czech/train/annotations/xmls\",\n",
    "                  \"RDD2022_all_countries/Norway/Norway/train/annotations/xmls\",\n",
    "                  \"RDD2022_all_countries/United_States/United_States/train/annotations/xmls\",\n",
    "]\n",
    "\n",
    "for CountryDir in CountryListDir:\n",
    "    \n",
    "    CountryDir = ROOTDIR + CountryDir\n",
    "\n",
    "    delete_nasty_files(CountryDir)\n",
    "\n",
    "    fileList = sorted(glob.glob(CountryDir + \"/*.xml\"))\n",
    "\n",
    "    # Processing all the annotation\n",
    "    for file in tqdm(fileList):\n",
    "\n",
    "        convertPascal2YOLOv8(file)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CopyDatasetSplit(baseDir):\n",
    "    \n",
    "    # Split the training data to train and validation data due to lack of annotation on test data\n",
    "    # Seed\n",
    "    random.seed(1337)\n",
    "    \n",
    "    # Output Directory\n",
    "    # !!! Change this to your clone folder\n",
    "    baseOutputDir = \"datasets/init_base\"\n",
    "    countryName = Path(baseDir).parents[0]\n",
    "    countryName = os.path.split(countryName)[1]\n",
    "    countryName = countryName.split('/')[0]\n",
    "\n",
    "    baseImageDir = baseDir + \"images/\"\n",
    "    baseAnnotDir = baseDir + \"labels/\"\n",
    "\n",
    "    image_list_all = sorted(glob.glob(baseImageDir + \"/*\"))\n",
    "    annot_list_all = sorted(glob.glob(baseAnnotDir + \"/*\"))\n",
    "\n",
    "    # Drop any images that doesnt have annotation (background)\n",
    "    # Or just leave it at some percentage of the dataset\n",
    "    backgroundImages_Percentage = 1\n",
    "    image_list = []\n",
    "    annot_list = []\n",
    "    \n",
    "    dataset_length_all = len(image_list_all)\n",
    "    max_background_image = int(dataset_length_all*backgroundImages_Percentage)\n",
    "    _counter = 0\n",
    "\n",
    "    for i in range(len(annot_list_all)):\n",
    "        \n",
    "        with open(annot_list_all[i]) as f:\n",
    "            _annot = f.read()\n",
    "\n",
    "            # Annotation not empty\n",
    "            if _annot:\n",
    "                image_list.append(image_list_all[i])\n",
    "                annot_list.append(annot_list_all[i])\n",
    "            elif _counter < max_background_image:\n",
    "                image_list.append(image_list_all[i])\n",
    "                annot_list.append(annot_list_all[i])\n",
    "                _counter = _counter + 1\n",
    "                \n",
    "    # Dataset length\n",
    "    dataset_length = len(image_list)\n",
    "    # print(dataset_length, len(annot_list))\n",
    "\n",
    "    split_ratio = 0.9\n",
    "    middle_point = round(split_ratio * dataset_length)\n",
    "\n",
    "    # Create random list number using seed\n",
    "    numberList = list(range(0, dataset_length))\n",
    "    random.shuffle(numberList)\n",
    "    trainNumberList = numberList[:middle_point]\n",
    "    validNumberList = numberList[middle_point:]\n",
    "    print(\"Training/Validation Samples :\", len(trainNumberList), len(validNumberList))\n",
    "\n",
    "    # Training images and labels\n",
    "    print(\"Copying training images and labels for\", countryName)\n",
    "    for i in tqdm(trainNumberList):\n",
    "\n",
    "        # Images\n",
    "        outputImagesDir = baseOutputDir + countryName + \"/images/train/\"\n",
    "        if not os.path.exists(outputImagesDir):\n",
    "            os.makedirs(outputImagesDir)\n",
    "\n",
    "        shutil.copy2(image_list[i], outputImagesDir)\n",
    "\n",
    "        # Annotations\n",
    "        outputAnnotDir = baseOutputDir + countryName + \"/labels/train/\"\n",
    "        if not os.path.exists(outputAnnotDir):\n",
    "            os.makedirs(outputAnnotDir)\n",
    "\n",
    "        shutil.copy2(annot_list[i], outputAnnotDir)\n",
    "        # print(outputImagesDir, outputAnnotDir)\n",
    "\n",
    "    # Validation images and labels\n",
    "    print(\"Copying validation images and labels for\", countryName)\n",
    "    for i in tqdm(validNumberList):\n",
    "\n",
    "        # Images\n",
    "        outputImagesDir = baseOutputDir + countryName + \"/images/val/\"\n",
    "        if not os.path.exists(outputImagesDir):\n",
    "            os.makedirs(outputImagesDir)\n",
    "\n",
    "        shutil.copy2(image_list[i], outputImagesDir)\n",
    "\n",
    "        # Annotations\n",
    "        outputAnnotDir = baseOutputDir + countryName + \"/labels/val/\"\n",
    "        if not os.path.exists(outputAnnotDir):\n",
    "            os.makedirs(outputAnnotDir)\n",
    "\n",
    "        shutil.copy2(annot_list[i], outputAnnotDir)\n",
    "        # print(outputImagesDir, outputAnnotDir)\n",
    "\n",
    "# baseDir = \"../dataset/RDD2022/RDD2022_all_countries/Japan/train/\"\n",
    "# CopyDatasetSplit(baseDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Validation Samples : 9455 1051\n",
      "Copying training images and labels for Japan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9455/9455 [00:06<00:00, 1457.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying validation images and labels for Japan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1051/1051 [00:00<00:00, 1183.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Validation Samples : 6935 771\n",
      "Copying training images and labels for India\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6935/6935 [00:04<00:00, 1469.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying validation images and labels for India\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 771/771 [00:00<00:00, 1499.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Validation Samples : 2161 240\n",
      "Copying training images and labels for China_Drone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [00:01<00:00, 1896.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying validation images and labels for China_Drone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:00<00:00, 2026.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Validation Samples : 2546 283\n",
      "Copying training images and labels for Czech\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2546/2546 [00:01<00:00, 1708.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying validation images and labels for Czech\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 283/283 [00:00<00:00, 1793.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Validation Samples : 7345 816\n",
      "Copying training images and labels for Norway\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7345/7345 [00:22<00:00, 321.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying validation images and labels for Norway\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 816/816 [00:02<00:00, 398.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Validation Samples : 4324 481\n",
      "Copying training images and labels for United_States\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4324/4324 [00:01<00:00, 2308.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying validation images and labels for United_States\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 481/481 [00:00<00:00, 2308.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Validation Samples : 1779 198\n",
      "Copying training images and labels for China_MotorBike\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1779/1779 [00:00<00:00, 2438.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying validation images and labels for China_MotorBike\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 198/198 [00:00<00:00, 2129.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Base Directory\n",
    "ROOTDIR = \"datasets_raw/\"\n",
    "\n",
    "# Use only japan india\n",
    "CountryListDir = [\"RDD2022_all_countries/Japan/Japan/train/\",\n",
    "                  \"RDD2022_all_countries/India/India/train/\",\n",
    "                  \"RDD2022_all_countries/China_Drone/China_Drone/train/\",\n",
    "                  \"RDD2022_all_countries/Czech/Czech/train/\",\n",
    "                  \"RDD2022_all_countries/Norway/Norway/train/\",\n",
    "                  \"RDD2022_all_countries/United_States/United_States/train/\",\n",
    "                  \"RDD2022_all_countries/China_MotorBike/China_MotorBike/train/\",\n",
    "]\n",
    "\n",
    "for CountryDir in CountryListDir:\n",
    "    CountryDir = ROOTDIR + CountryDir\n",
    "    CopyDatasetSplit(CountryDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Train_size</th>\n",
       "      <th>Val_size</th>\n",
       "      <th>Total_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japan</td>\n",
       "      <td>9455</td>\n",
       "      <td>1051</td>\n",
       "      <td>10506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India</td>\n",
       "      <td>6935</td>\n",
       "      <td>771</td>\n",
       "      <td>7706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Czech</td>\n",
       "      <td>2546</td>\n",
       "      <td>283</td>\n",
       "      <td>2829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Norway</td>\n",
       "      <td>7345</td>\n",
       "      <td>816</td>\n",
       "      <td>8161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United_States</td>\n",
       "      <td>4324</td>\n",
       "      <td>481</td>\n",
       "      <td>4805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>China_MotorBike</td>\n",
       "      <td>1779</td>\n",
       "      <td>198</td>\n",
       "      <td>1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>China_Drone</td>\n",
       "      <td>2161</td>\n",
       "      <td>240</td>\n",
       "      <td>2401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Country  Train_size  Val_size  Total_size\n",
       "0            Japan        9455      1051       10506\n",
       "1            India        6935       771        7706\n",
       "2            Czech        2546       283        2829\n",
       "3           Norway        7345       816        8161\n",
       "4    United_States        4324       481        4805\n",
       "5  China_MotorBike        1779       198        1977\n",
       "6      China_Drone        2161       240        2401"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = ['Japan',\n",
    "             'India',\n",
    "             'Czech',\n",
    "             'Norway',\n",
    "             'United_States',\n",
    "             'China_MotorBike',\n",
    "             'China_Drone']\n",
    "\n",
    "dataset_size = list()\n",
    "\n",
    "# declare list that stores records\n",
    "records = list()\n",
    "\n",
    "for country in countries:\n",
    "    path_train = f'datasets/init_base{country}/images/train'\n",
    "    path_val = f'datasets/init_base{country}/images/val'\n",
    "\n",
    "    record = dict()\n",
    "    record['Country'] = country\n",
    "    record['Train_size'] = len(os.listdir(path_train)) if os.path.exists(path_train) else 0\n",
    "    record['Val_size'] = len(os.listdir(path_val)) if os.path.exists(path_val) else 0\n",
    "\n",
    "    # save record\n",
    "    records.append(record)\n",
    "\n",
    "records = pd.DataFrame(records)\n",
    "records['Total_size'] = records['Train_size'] + records['Val_size']\n",
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Train_size    34545\n",
       "Val_size       3840\n",
       "Total_size    38385\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.drop(columns = 'Country').sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
